#!/usr/bin/env python

# the gallery that inspired me to create this script:
# https://imgur.com/gallery/SwhjO

import os
import re

from urllib2 import urlopen
from HTMLParser import HTMLParser
from argparse import ArgumentParser


class Arguments():
    url = None
    path = None

    def __init__(self):
        self._parse_args()

    def _parse_args(self):
        parser = ArgumentParser()

        parser.add_argument("url",
                            type=str,
                            metavar='N',
                            nargs=1,
                            help="ImgUr gallery URL")
        parser.add_argument("--path",
                            "-p",
                            type=str,
                            default=os.getcwd(),
                            help="Path to save images (default: current)")
        parser.add_argument("--limit",
                            "-l",
                            type=int,
                            default=0,
                            help="Limit the number of images to download\
                            (default: 0, all images)")

        args = parser.parse_args()

        self.url = args.url[0].strip()
        self.path = args.path.strip()
        self.limit = args.limit


class ImgUrParser(HTMLParser):

    def __init__(self):
        # disclaimer: HTMLParser is old style class, do not support 'super'
        # initialization style :/
        HTMLParser.__init__(self)

        self._images = []

    def _validate_url(self, url):
        regex = ur'http[s]?://(?:w{3}\.)?imgur.com/(?:[a-zA-Z]|[0-9]|[$-_@.&+]\
                |[!*\(\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))*'

        return re.match(regex, url)

    def _validate_image(self, image):
        regex = ur'.*(?:.png|.jpg)$'

        return re.match(regex, image)

    def parse(self, url):
        # check if url is a valid ImgUr address
        if not self._validate_url(url):
            print "URL '%s' doesn't seems to be a valid ImgUr address" % url
            return

        print "Parsing %s" % url

        try:
            f = urlopen(url)
            html = f.read()
            f.close()
        except Exception as e:
            print ">> Error; is it a valid URL? (%s)" % e
            return

        try:
            html = self.unescape(html)
        except Exception as e:
            print ">> Error: %s" % e
            return

        try:
            self.feed(html)
        except Exception as e:
            print ">> Error: %s" % e
            return

        print "    Found %s images" % len(self._images)

    def handle_starttag(self, tag, attrs):
        if tag == "a":
            for attr, value in attrs:
                if attr == "href" and self._validate_image(value):
                    self._images.append("https:%s" % value)  # TODO get http/https from url

    def images(self):
        return self._images


class Downloader():

    def __init__(self, path, name):
        self._path = path if path != str() else "./"
        self._name = name

        self._download_path = os.path.join(path, dir_name)

    def download(self, images=[], limit=0):
        if not images:
            return

        if not os.path.exists(self._path):
            print "> Path '%s' doesn't exist" % self._path
            return

        if not os.path.exists(self._download_path):
            print "Creating %s/ on %s" % (self._name, self._path)
            try:
                os.mkdir(self._download_path)
            except Exception as e:
                print ">> Error: %s" % e
                return

        print "Downloading images to %s/" % self._download_path
        if limit > 0:
            images = images[:limit]
            print "    (limiting download to %s images)" % limit

        num_images = len(images)
        for index, image in enumerate(images):
            image_file = image.split('/')[-1]

            print "    (%s/%s) %s..." % (index + 1, num_images, image_file)

            image_file = os.path.join(self._download_path, image_file)
            if os.path.isfile(image_file):
                print "        File already exists, skipping..."
                continue

            try:
                f = open(image_file, 'wb')
                f.write(urlopen(image).read())
                f.close()
            except Exception as e:
                print ">> Error: %s" % e
                return


if __name__ == '__main__':
    arguments = Arguments()

    url = arguments.url

    parser = ImgUrParser()
    parser.parse(url)

    dir_name = url.split('/')[-1]

    downloader = Downloader(arguments.path, dir_name)
    downloader.download(parser.images(), arguments.limit)
