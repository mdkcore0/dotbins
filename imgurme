#!/usr/bin/env python

# the gallery that inspired me to create this script:
# https://imgur.com/gallery/SwhjO

import sys
import os
import re

from urllib2 import urlopen
from HTMLParser import HTMLParser
from argparse import ArgumentParser


class Arguments():
    url = None
    path = None

    def __init__(self):
        self._parse_args()

    def _parse_args(self):
        parser = ArgumentParser()

        parser.add_argument("url",
                            type=str,
                            metavar='N',
                            nargs=1,
                            help="ImgUr gallery URL")
        parser.add_argument("--path",
                            "-p",
                            type=str,
                            help="Path to save images (default: current)")

        args = parser.parse_args()

        self.url = args.url[0]
        self.path = os.getcwd() if args.path == None else args.path


class ImgUrParser(HTMLParser):

    def __init__(self):
        # disclaimer: HTMLParser is old style class, do not support 'super'
        # initialization style :/
        HTMLParser.__init__(self)

        self._images = []

    def parse(self, url):
        print "Parsing %s" % url

        try:
            f = urlopen(url)
            html = f.read()
            f.close()
        except Exception as e:
            print ">> Error; is it a valid URL? (%s)" % e
            return

        html = self.unescape(html)
        self.feed(html)

        print "    Found %s images" % len(self._images)

    def handle_starttag(self, tag, attrs):
        if tag == "a":
            for attr, value in attrs:
                # XXX regex to get jpg files
                if attr == "href" and value.endswith(".jpg"):

                    self._images.append("https:%s" % value)

    def images(self):
        return self._images


class Downloader():

    def __init__(self, path, name):
        self._path = path
        self._name = name

        self._download_path =  os.path.join(path, dir_name)

    def download(self, images=[]):
        if not images:
            return

        num_images = len(images)

        if not os.path.exists(self._download_path):
            print "Creating %s/ on %s" % (self._name, self._path)
            # TODO exception (no such dir)
            os.mkdir(self._download_path)

        print "Downloading images to %s/" % self._download_path

        for index, image in enumerate(images):
            image_file = image.split('/')[-1]

            print "    (%s/%s) %s..." % (index + 1, num_images, image_file)

            image_file = os.path.join(self._download_path, image_file)
            if os.path.isfile(image_file):
                print "        File already exists, skipping..."
                continue

            try:
                f = open(image_file, 'wb')
                f.write(urlopen(image).read())
                f.close()
            except Exception as e:
                print ">> Error (%s)" % e
                return


if __name__ == '__main__':
    arguments = Arguments()

    url = arguments.url

    parser = ImgUrParser()
    parser.parse(url)

    dir_name = url.split('/')[-1]

    downloader = Downloader(arguments.path, dir_name)
    downloader.download(parser.images())
